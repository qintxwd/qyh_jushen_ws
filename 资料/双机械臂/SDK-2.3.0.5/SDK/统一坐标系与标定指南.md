# 统一坐标系与标定指南（双臂 + 可转头摄像头）

本文档面向节卡双臂机器人：左右机械臂分别安装在机器人左右肩膀，头部可左右转动并装有摄像头。目标：统一各个传感器与执行器的坐标系，保证视觉检测、抓取规划、双臂同步运动能正确地在同一世界坐标系下工作。

目录
- 概述
- 约定与命名规范
- 坐标变换基础（齐次变换、四元数、旋转矩阵）
- 头部（pan）旋转的建模与实时处理
- 相机与末端执行器的配准（手眼/eye-to-hand 标定）
- 双臂协作中的坐标链（从相机到左右 TCP 的变换）
- 标定与实现步骤（数据采集、求解、验证）
- 实际工作流与伪代码
- 验证与误差度量
- 常见问题与调优建议

---

## 概述

要点：把相机、左臂、右臂、基座（机器人身体）以及头部（包含pan轴）的坐标系放到统一的参考系下（World/Base）。统一坐标系的核心是建立一组稳定的变换矩阵（4x4 齐次变换），并在运行时按正确顺序组合它们。

术语：
- Base（或 World）：机器人身体固定原点，作为全局参考。
- Shoulder_L / Shoulder_R：左右机械臂在肩部的基准坐标系（通常是机械臂的第1关节基座）。
- TCP_L / TCP_R：左右臂末端工具坐标（夹具中心，Tool Center Point）。
- Head_mount：头部固定安装点（相对于 Base 的静态变换，不含pan角度）。
- Head_pan：头部旋转（绕垂直或给定轴的实时旋转）。
- Camera：相机的坐标系（通常相机光轴为 Z，x,y按相机约定）。
- Object：相对于相机检测到的物体坐标（或物体在世界坐标系下的位置）。

注意：所有位置单位请统一为毫米（mm），角度统一为弧度（rad），使用右手坐标系（如果控制器与相机习惯不同，请在约定部分写明并转换）。

---

## 约定与命名规范

建议的命名（统一且可读）：
- `base` 或 `world`
- `shoulder_l`, `shoulder_r`  （肩部/臂基座）
- `wrist_l`, `wrist_r`（手腕/关节末端）
- `tcp_l`, `tcp_r`（工具坐标）
- `head_mount`（头部固定底座）
- `head_pan`（头部旋转关节）
- `cam` 或 `camera`（相机坐标系）
- `object`（识别到的物体）

每个变换都用齐次矩阵 T_{A}^{B} 表示：把坐标从 A 系表达成 B 系（常写成 T_B_A，或 T_{B<-A}）。在文档中采用：

T_base_headmount: 把 head_mount 相对于 base 的静态位姿（4x4）
R_pan(theta): 头部绕某轴的旋转矩阵（由实时pan角度theta给出）
T_head_cam: 相机相对于 head_mount 的固定外参（当相机固定在头上）

组合规则（从相机到 base）：

T_base_cam(theta) = T_base_headmount * R_pan(theta) * T_head_cam

若要把相机观测的物体点 p_cam 转换到 base：

p_base = T_base_cam(theta) * p_cam

（齐次坐标下 p_cam 为 [x y z 1]^T）

---

## 坐标变换基础（快速参考）

1. 齐次变换矩阵（4x4）：

T = [ R  t ]
    [ 0  1 ]

其中 R: 3x3 旋转矩阵，t: 3x1 平移向量。

2. 坐标变换：

p_B = T_B_A * p_A

3. 旋转组合：

R_total = R1 * R2（注意旋转矩阵的乘法次序与坐标系变换方向有关）

4. 四元数与旋转矩阵相互转换可以用常见的库（Eigen、OpenCV、tf等）。

5. 求逆（变换的逆）：

T^{-1} = [ R^T  -R^T t ]
         [  0      1   ]

---

## 头部（pan）旋转的建模与实时处理

场景：头部挂在 `head_mount` 点，但头部有一个可转轴（pan），角度为 θ（可以由控制器读到或由驱动器/编码器回传）。头部上的相机相对 `head_mount` 有一个固定外参 T_head_cam。

建模方法：
1. 获取静态外参 T_base_headmount（通过机械测量或在机器人坐标系中标定得到）。
2. 在运行时读取 pan 角度 θ（记得单位与方向），构造绕指定轴的旋转矩阵 R_pan(θ)。轴可能是 `head_mount` 坐标系下的 z 轴或其它已知轴。
3. 组合出：

T_base_cam(θ) = T_base_headmount * R_pan(θ) * T_head_cam

这样任何时候用当前θ计算出的 T_base_cam 都是最新的相机位姿。

注意时间同步：
- 若相机图像帧和 pan 编码器读数不是严格同步，需用时间戳插值/补偿，或以时间戳对齐数据。

---

## 相机与末端执行器的配准（手眼 / eye-to-hand 标定）

两种常见情形：

A. Eye-in-hand（手眼）：相机装在机械臂末端（随手臂移动）。目标：求解相机相对于手臂末端的静态外参 X（即 T_end_cam）。常见方程为 AX = XB（Tsai-Lenz 等方法）。

B. Eye-to-hand（外部相机/固定在头上）：相机固定在机器人身体（或头部）。目标：求相机到机器人基座（或臂基座）的外参 T_base_cam。

在你的场景中：相机固定在头并随 pan 旋转，属于 eye-to-hand（但包含一个旋转轴），可以把手眼方法用于获取 T_head_cam（相机相对 head_mount 的外参），再用头部静态位置+pan角确定相对 base 的变换。

手眼标定关键点（若需要手眼算法）：
- 收集 N 组数据对 (A_i, B_i)：A_i = 末端位姿（相对于 base 的变换，由 robot 得到），B_i = 相机观测到棋盘/标定板的位姿（相对于相机）。
- 求解 X：使得 A_i * X = X * B_i （或 AX = XB 形式，具体符号取决于定义）。
- 常用实现：OpenCV 的 `calibrateHandEye`（支持多种算法：Tsai、Park、Horaud 等）。

对于 head+pan 的情形，推荐流程：
1. 标定相机相对 head_mount（静态外参）T_head_cam：将头部固定（pan=0）或在已知 pan 角下做多组观测，利用标定板在不同位置拍摄并用 `solvePnP` 得到相机->board 位姿，结合 head_mount->base 与 robot 运动数据可反算T_head_cam。
2. 确保你能读取 pan 角度并计算 R_pan(θ)。
3. 组合出 T_base_cam(θ) 用于实时定位。

更直接的做法（推荐）:
- 在多组已知 pan 角 θ_i 下采集相机观测与机器人基座/手臂位置（如果采集到同一标定板）。
- 对于每组观测，得到相机->board（或board->cam），以及 robot 的相关变换。利用手眼标定方法求解静态部分 T_head_cam 与头部安装偏置。

---

## 双臂协作中的坐标链（从相机到左右 TCP）

总体变换链（目标是把物体/夹持点 p_object 转换到左右 TCP 或关节的目标）:

1. 从相机像素检测 -> 解算出 p_cam（物体在相机坐标系的位置与姿态）
2. p_base = T_base_cam(θ) * p_cam
3. 要把物体夹持点 p_base 转换到左/右臂的 TCP 目标（通常 TCP 相对于物体点会有一个偏移 e.g. 夹具夹住物体某处）：

p_tcp_target_l = T_base_tcp_l^{-1} * p_base_desired_l  （或直接用逆变换求目标关节）

实际上更常用的方式：
- 计算左右臂末端的期望笛卡尔位姿 pose_l_base, pose_r_base（齐次矩阵），然后使用逆运动学得到关节角度。
- pose_l_base = T_base_obj * T_obj_tcp_l （注意顺序）

其中 T_obj_tcp_l 是物体到左臂TCP的相对变换（由夹持几何决定）。

---

## 标定与实现步骤（详细实施指南）

下面给出一个逐步实现流程，覆盖测量、标定、实现、验证。

### 步骤 0：前提准备
- 确保机器人 SDK 能读取如下信息：
  - 机器人基座到肩部/关节的静态变换（或至少能用关节位姿+正运动学得到wrist位置）。
  - 头部 pan 角度（实时）
  - 相机图像以及时间戳
- 准备一个标定板（棋盘或圆形网格），并能在相机视野中检测并估计其在相机坐标系下的位姿（OpenCV solvePnP 常用）。

### 步骤 1：测量 / 粗标定（获得 T_base_headmount）
- 用量具人工测量或通过机器人已知几何关系获得 `T_base_headmount`（head 底座相对于 base 的静态变换）。如果测量困难，可用下面的标定方法联合求解。

### 步骤 2：相机内参与畸变标定
- 用 OpenCV 的 `calibrateCamera` 对相机做内参、畸变标定，得到相机矩阵 K 与畸变系数。
- 这一步保证后续的 solvePnP 结果准确。

### 步骤 3：求解 T_head_cam（相机相对于 head_mount 的外参）
两种方式：

A. 若 head 安装固定且能将 pan 角度设置为 0：
- 将头部置于已知 panθ（例如 0），把标定板放在若干位置，拍摄并用 solvePnP 得到 board->cam。
- 同时记录 robot 的 head_mount 在 base 的位置（若机器人能直接给出head_mount在base的位姿则直接使用），否则人工测量补充。
- 解算得到 T_head_cam。

B. 若 head 会动且更稳健的方法（推荐）：
- 在多个 pan 角度 θ_i 和若干标定板位置下采集数据。
- 对于每组数据，记录：pan θ_i, camera->board（由 solvePnP 得到），以及 robot（某参考点如 head_mount）在 base 中的位姿或关节角（便于构造head_mount到base）。
- 使用手眼标定/最小二乘求解整体外参。

实践中，OpenCV 的 `calibrateHandEye` 非常方便：
- 采集一组 A_i（末端或head相对于 base 的变换）和 B_i（相机观测到标定板的变换），然后调用 `calibrateHandEye` 求解 X（手眼外参）。

### 步骤 4：验证 T_base_cam(θ)
- 在若干已知位置放一个标定物（或 fiducial），用相机观测并把其 p_cam 转换到 base（使用 T_base_cam(θ)）。
- 用已知的物理测量值对比以验证误差。

### 步骤 5：夹持点与夹具TCP标定
- 在夹具安装完成后，标定 TCP（`robot_set_tool_offset`）：测量夹具中心相对于手腕法兰的偏置或使用夹具标定程序（例如让臂指向已知点并求解偏置）。
- 设置完 TCP 后，用 `robot_get_tool_offset` 验证。

### 步骤 6：计算左右夹持位姿并求解逆解
- 给定物体在 base 下的位置与姿态 T_base_obj，以及左右夹持点相对物体的固定变换（T_obj_tcp_l, T_obj_tcp_r），计算：

pose_l_base = T_base_obj * T_obj_tcp_l
pose_r_base = T_base_obj * T_obj_tcp_r

- 通过 `kine_inverse(LEFT, &ref_joint, &pose_l_base, &joint_l)` 求解左臂关节解；同理右臂。
- 若逆解失败（超出工作空间），需要调整抓取点或姿态。

### 步骤 7：规划与同步运动
- 使用 `robot_run_multi_movj` 或 `robot_run_multi_movl` 以 DUAL 或 -1 同步控制两臂。注意使用相同的速度/加速度参数以获得更好的同步性。
- 对于对中要求高的夹持，建议使用运动到位检测并在两臂都 inpos 后再执行夹具闭合动作。

### 步骤 8：闭合夹具并提升
- 控制夹具 IO 闭合（`robot_set_io` 或控制外部夹具控制器），并读回夹具状态确认夹紧。
- 缓慢提升并检测是否有位移或力异常（如果有力传感器，可在提升时监控负载是否均匀）。

---

## 实际工作流（伪代码）

以下伪代码假设：
- 你能获得当前 pan 角度 `theta`，并能通过函数 `get_camera_pose_in_base(theta)` 返回 `T_base_cam`。
- 相机检测模块给出 `T_cam_obj`（物体相对于相机位姿）。
- 已有事先定义好的 `T_obj_tcp_l` 与 `T_obj_tcp_r`（物体→两臂TCP的相对位姿）。

伪代码：

```
// 1. 读取当前头部pan角度
theta = read_head_pan_angle();

// 2. 计算相机在base下的位姿
T_base_cam = T_base_headmount * R_pan(theta) * T_head_cam;

// 3. 相机检测物体 -> 得到物体在相机系的位姿
T_cam_obj = detect_object_pose_from_image();

// 4. 将物体变换到base系
T_base_obj = T_base_cam * T_cam_obj;

// 5. 计算左右臂目标位姿
pose_l_base = T_base_obj * T_obj_tcp_l; // 物体->左端TCP的逆
pose_r_base = T_base_obj * T_obj_tcp_r;

// 6. 逆运动学求解
ret_l = robot.kine_inverse(LEFT, &ref_joint_l, &pose_l_base, &joint_l);
ret_r = robot.kine_inverse(RIGHT, &ref_joint_r, &pose_r_base, &joint_r);
if (ret_l != ERR_SUCC || ret_r != ERR_SUCC) {
    // 处理逆解失败：调整抓取姿态或放弃
}

// 7. 同步运动到抓取位
robot.robot_run_multi_movj(DUAL, move_mode, TRUE, joint_target_pair, vel, acc);

// 8. 等待两臂到位(inpos)
wait_until_both_inpos();

// 9. 控制夹具闭合（IO）
set_gripper_io(LEFT, CLOSE);
set_gripper_io(RIGHT, CLOSE);

// 10. 验证夹具状态并提升
if (grippers_ok()) {
    // 抬起并移动到目标位置
    robot.robot_run_multi_movj(DUAL, move_mode, TRUE, lift_joint_pair, vel, acc);
}
```

---

## 代码实现建议与库

- 图像检测与位姿估计：OpenCV (`solvePnP`, `calibrateCamera`, `calibrateHandEye`)。
- 矩阵与线性代数：Eigen 或内置矩阵库（或把小矩阵自己实现）。
- 时间同步：用图像时间戳对齐 pan 编码器/电机读数。
- 标定脚本：建议用 Python（OpenCV + numpy）快速实现数据采集与求解，然后将结果固化到机器人控制流程中。

### OpenCV `calibrateHandEye` 使用提示
- 采集 A_i（末端位姿）与 B_i（相机观测板位姿）对。
- 选择 `CALIB_HAND_EYE_TSAI` 或 `CALIB_HAND_EYE_HORAUD` 算法。

---

## 验证与误差度量

- 位置误差：||p_base_measured - p_base_expected||（mm）
- 姿态误差：用角轴或四元数度量（deg 或 rad）
- 建议：目标位置误差 < 5mm（取决于夹具精度与物体尺寸），姿态误差 < 1度

测试用例：
1. 静态物体：多次观测并抓取，统计误差与成功率
2. 轻微姿态变化物体：测试容错性
3. 头部不同 pan 角度：在多角度下重复标定与抓取验证

---

## 常见问题与调优建议

- 相机与头部编码器不同步 → 使用时间戳插值或在图像采集后立刻读pan角（注意延迟）。
- 夹具TCP标定不准 → 使用物理测量+小量程调优；做重复性试验验证。
- 逆解失败或奇异 → 调整夹持姿态、降低对位精度要求或使用中间姿态（先退后进）。
- 力控与夹紧不均匀 → 在夹持时使用力传感器做闭环力控（若支持）。

---

## 结论与下一步建议

1. 首先完成相机内参与外参（T_head_cam）标定，并保证能读取实时 pan 角度。
2. 标定并设置左右 TCP 以及负载参数（`robot_set_tool_payload`）。
3. 实现从相机检测到物体 -> 转基坐标 -> 计算左右抓取位姿 -> 逆解 -> 同步运动 -> 夹持的完整流水线。
4. 逐步开展验证用例，记录误差并迭代优化（相机参数、TCP、运动参数、碰撞等级）。

如果你愿意，我可以：
- 为你生成一个具体的手眼标定数据采集脚本（Python + OpenCV），包含如何读取机器人位姿和相机图像并保存A_i/B_i对；
- 或者生成一个 C++/Python 的示例，展示如何把相机检测结果转换到 base，再调用 `kine_inverse` 和 `robot_run_multi_movj` 完成夹取动作。

请选择你需要的下一步（例如：生成标定脚本 / 生成抓取示例代码 / 帮你把文档内的伪代码改成可运行脚本）。
